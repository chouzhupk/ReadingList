# ReadingList
Paper and talk grass list.

### 06072017

Leaky relu

[Res Net read again](https://arxiv.org/pdf/1512.03385.pdf)

[Know about floating numbers](http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html)

#### Batch-size selections:
[basic hyper-parameters](http://cs231n.github.io/neural-networks-3/)

[Practical Recommendations for Gradient-Based Training of Deep Architectures](https://arxiv.org/pdf/1206.5533.pdf)

[Stochastic Gradient Descent Tricks](https://www.microsoft.com/en-us/research/wp-content/uploads/2012/01/tricks-2012.pdf)

[Efficient BackProb](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)

[Efficient Mini-batch Training for Stochastic Optimization](http://www.cs.cmu.edu/~muli/file/minibatch_sgd.pdf)

[Optimization Methods for Large-Scale Machine Learning](https://arxiv.org/abs/1606.04838)

[On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima](https://arxiv.org/pdf/1609.04836.pdf)

https://stats.stackexchange.com/questions/140811/how-large-should-the-batch-size-be-for-stochastic-gradient-descent

https://www.quora.com/Intuitively-how-does-mini-batch-size-affect-the-performance-of-stochastic-gradient-descent

https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network




### 06062017

[Very Deep Convolutional Networks for Text Classification](https://arxiv.org/pdf/1606.01781.pdf)

### Long time no read

[optimizing-gradient-descent](http://sebastianruder.com/optimizing-gradient-descent/)

[Exploring the Limits of Language Modeling](https://arxiv.org/pdf/1602.02410.pdf)



## History List
[Topics in ML](https://www.cs.toronto.edu/~duvenaud/courses/csc2541/index.html)

##This Semester
[Visual Dialog](https://arxiv.org/pdf/1611.08669v2.pdf)

[ORDER-EMBEDDINGS OF IMAGES AND LANGUAGE](https://arxiv.org/pdf/1511.06361v6.pdf)

[Learning Aligned Cross-Modal Representations from Weakly Aligned Data](http://www.cs.toronto.edu/~castrejon/content/cvpr2016.pdf)

[Pixel Recursive Super Resolution](https://arxiv.org/pdf/1702.00783v1.pdf) 

[Tutorial on GAN](https://arxiv.org/pdf/1701.00160v3.pdf)

[NIPS 2016 GAN Papers](https://sites.google.com/site/nips2016adversarial/home/accepted-papers)

[Generating Text via Adversarial Training](https://c4209155-a-62cb3a1a-s-sites.googlegroups.com/site/nips2016adversarial/WAT16_paper_20.pdf?attachauth=ANoY7cpDgqvVi1CaTdC4YxVV7h-CfamMefA7wgvpcFFKnycvhSzluG6nOHAjy7Tp1bCIPsruuWBTKaNbZTgnEolWqBGaI7SiFefiS0otYRUM_fu-Fd1lMgLBK6uJHHGPOzTi85LDj4Pj_DpTeGbGTKWDSHbjCMT4XcIiMUONvwicj4wxwf1y1X1greT0T2DmBtmIjh6e1WfFCHKWwBslkh57PqKbD-Z2bnkINNeyJ8Ndj9vEkOPn_FM%3D&attredirects=0)

[Skip-Thought Vectors](https://arxiv.org/pdf/1506.06726.pdf)

[GAN](http://datascienceassn.org/sites/default/files/Generative%20Adversarial%20Nets.pdf)

[Modeling documents with Generative Adversarial Networks](https://c4209155-a-62cb3a1a-s-sites.googlegroups.com/site/nips2016adversarial/WAT16_paper_19.pdf?attachauth=ANoY7cpiEhgAdlzMTtlEVkXEJqYZj9yRyLYZ_pw4OyrFE9OhT_qu7TOZPgmGgu5u3GYb6oz_uqVWEF5zGzzVUVadoWD_qaKRys2vovtk8RPtS_b2JqZP2YVbu6SdAwXi_1bn2XUfO2xIYQ-LP4SpR3-Yjq_n1tN9vIm3uGG5A2LXJcSkzMDIvZO7ojMyWkusYwhXZu3zLNem7JazCSoBCfSKGOlw4jU_6vLY5OhI_fm8vOL1r9PefBI%3D&attredirects=0)

[Tony Wu](https://arxiv.org/pdf/1611.04273.pdf)
###Language & RNN

[Distributed Representations of Sentences and Documents](http://cs.stanford.edu/~quocle/paragraph_vector.pdf)

###Recommendations
[NetEase](http://bmc.uestc.edu.cn/~zhangdongxiang/papers/ICDE16_industry_231.pdf)

[Maksims_1](https://pdfs.semanticscholar.org/c52e/f5426715984b1c6440a582499a549d33e4ce.pdf)

[Effective Latent Models for Binary Feedback in Recommender Systems](https://pdfs.semanticscholar.org/49ee/8a342cb3676f334165aa2dd05fab995c00f7.pdf)

[SESSION-BASED RECOMMENDATIONS WITH RECURRENT NEURAL NETWORKS](https://arxiv.org/pdf/1511.06939.pdf)
## Videos
[Ruslan's Tutorial in Deep Learning](https://simons.berkeley.edu/talks/tutorial-deep-learning)

[Stanford NLP Deep Learning syllabus](http://cs224d.stanford.edu/syllabus.html)

[Stanford NLP Deep Learning video list](https://www.youtube.com/playlist?list=PLlJy-eBtNFt4CSVWYqscHDdP58M3zFHIG)

## For Sanja's Project

[VQA overview](https://arxiv.org/pdf/1607.05910.pdf)

[Multi-labeled CNN](https://arxiv.org/pdf/1406.5726.pdf)

### Follow up of VQA Overview
(https://arxiv.org/pdf/1511.02799.pdf)

(https://cs.stanford.edu/people/karpathy/nips2014.pdf)

(https://arxiv.org/pdf/1505.02074.pdf)

(https://arxiv.org/pdf/1506.07285.pdf)

(https://arxiv.org/pdf/1603.01417.pdf)

***(https://arxiv.org/pdf/1511.06973.pdf)***

***(https://arxiv.org/pdf/1505.05612.pdf)***

***(https://arxiv.org/pdf/1606.01847.pdf)***

[UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS](https://arxiv.org/pdf/1511.06434.pdf)

=======================================================================================

(https://arxiv.org/pdf/1511.05960.pdf)

(https://arxiv.org/pdf/1602.04341.pdf)

(https://arxiv.org/pdf/1512.05193.pdf)

(https://arxiv.org/pdf/1502.03044.pdf)

**[Stacked Attention Networks for Image Question Answering](https://arxiv.org/pdf/1511.02274.pdf)

(https://arxiv.org/pdf/1610.01076.pdf)
